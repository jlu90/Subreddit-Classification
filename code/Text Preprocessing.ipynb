{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Steps:\n",
    "1. Remove Special Characters\n",
    "2. Tokenize\n",
    "3. Lemmatize/Stem\n",
    "4. Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = pd.read_csv('../data/subreddits_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>total_text</th>\n",
       "      <th>post_length_char</th>\n",
       "      <th>post_length_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Answers to why</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>AlienAgency</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>Answers to why</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>多Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>GarbageMiserable0x0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>多Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Soothe digestion with lemongrass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>thaigrrrrrrr</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>Soothe digestion with lemongrass</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title selftext  \\\n",
       "0           0                                     Answers to why      NaN   \n",
       "1           1  多Quieres obtener juegos y premios gratis en tu...      NaN   \n",
       "2           2                   Soothe digestion with lemongrass      NaN   \n",
       "\n",
       "     subreddit               author  num_comments  score   timestamp  \\\n",
       "0  LifeProTips          AlienAgency             2      1  2020-07-17   \n",
       "1  LifeProTips  GarbageMiserable0x0             2      1  2020-07-17   \n",
       "2  LifeProTips         thaigrrrrrrr             2      1  2020-07-17   \n",
       "\n",
       "                                          total_text  post_length_char  \\\n",
       "0                                     Answers to why                15   \n",
       "1  多Quieres obtener juegos y premios gratis en tu...                60   \n",
       "2                   Soothe digestion with lemongrass                33   \n",
       "\n",
       "   post_length_words  \n",
       "0                  3  \n",
       "1                 10  \n",
       "2                  4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "    \"aren't\": 'are not',\n",
    "    \"can't\": 'cannot',\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\", \n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"I'd\": \"i would\",\n",
    "    \"I'll\": \"i will\",\n",
    "    \"I am\": \"i'm\",\n",
    "    \"I've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"she'd\":\"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'll\":\"they will\",\n",
    "    \"they're\": \"they are\", \n",
    "    \"they've\": \"they have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\", \n",
    "    \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Answers to why'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function Written By Dipanjan Sarkar \n",
    "# https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=contractions):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(subreddits['total_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tokens = []\n",
    "\n",
    "for post in subreddits['total_text']:\n",
    "    post_tokens.append(word_tokenize(post.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "post_lemma_tokens = []\n",
    "\n",
    "for token in post_tokens:\n",
    "    running_lemma_tokens = []\n",
    "    for word in token:\n",
    "        running_lemma_tokens.append(lemmatizer.lemmatize(word))\n",
    "    post_lemma_tokens.append(running_lemma_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'ever',\n",
       " 'lonely',\n",
       " ',',\n",
       " 'try',\n",
       " 'writing',\n",
       " '.',\n",
       " 'whether',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'in',\n",
       " 'a',\n",
       " 'journal',\n",
       " ',',\n",
       " 'a',\n",
       " 'letter',\n",
       " 'to',\n",
       " 'someone',\n",
       " 'or',\n",
       " 'a',\n",
       " 'story',\n",
       " '-',\n",
       " 'the',\n",
       " 'act',\n",
       " 'of',\n",
       " 'putting',\n",
       " 'word',\n",
       " 'to',\n",
       " 'paper',\n",
       " 'will',\n",
       " 'make',\n",
       " 'you',\n",
       " 'feel',\n",
       " 'le',\n",
       " 'alone',\n",
       " ':',\n",
       " ')']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_lemma_tokens[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
