{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = pd.read_csv('../data/subreddits_preprocessed.csv')\n",
    "subreddits.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>original_text</th>\n",
       "      <th>post_length_char</th>\n",
       "      <th>post_length_words</th>\n",
       "      <th>is_unethical</th>\n",
       "      <th>stemmer_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: Answers to why</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>AlienAgency</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>: Answers to why</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>: answer to whi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>GarbageMiserable0x0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>¿Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>¿quier obten juego y premio grati en tu tiempo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title selftext    subreddit  \\\n",
       "0                                   : Answers to why      NaN  LifeProTips   \n",
       "1  ¿Quieres obtener juegos y premios gratis en tu...      NaN  LifeProTips   \n",
       "\n",
       "                author  num_comments  score   timestamp  \\\n",
       "0          AlienAgency             2      1  2020-07-17   \n",
       "1  GarbageMiserable0x0             2      1  2020-07-17   \n",
       "\n",
       "                                       original_text  post_length_char  \\\n",
       "0                                   : Answers to why                16   \n",
       "1  ¿Quieres obtener juegos y premios gratis en tu...                60   \n",
       "\n",
       "   post_length_words  is_unethical  \\\n",
       "0                  4             0   \n",
       "1                 10             0   \n",
       "\n",
       "                                        stemmer_text  polarity sentiment_cat  \n",
       "0                                    : answer to whi       0.0       Neutral  \n",
       "1  ¿quier obten juego y premio grati en tu tiempo...       0.0       Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate set of models, I determined that stemmed text and the Tfidf Vectorizer would be a good choice for my data. Therefore, I will conduct a train test split on the stemmed text and set up a Column Transformer to only vectorize my text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['num_comments', 'score', 'post_length_char', 'post_length_words', 'stemmer_text']\n",
    "#features = ['stemmer_text']\n",
    "X = subreddits[features]\n",
    "y = subreddits['is_unethical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for Multinomial Bayes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bayes = subreddits[['stemmer_text']]\n",
    "y_bayes = subreddits['is_unethical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bayes_train, X_bayes_test, y_bayes_train, y_bayes_test = train_test_split(X_bayes, y_bayes, test_size = 0.3, random_state = RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Stop Words Hyperparameter for Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = ['someon', 'll', 'like', 'know', 'ulpt', 'lpt', 'need', 'use', 'make', 'wa', 'way', 'peopl', 'ask', 'say', 'time', 'thi', 'want', 'work', 'just', 'start', 'ha', 'tri', 'becaus', 'onli', 'friend']\n",
    "nltk_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Column Transformer to Only Apply Vectorizer to Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(), 'stemmer_text'),], \n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARKDOWN TO DESCRIBE THE PROCESS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy_scores(model, xtrain, ytrain, xtest, ytest):\n",
    "    print(f'The cross validation accuracy score is {round(cross_val_score(model, xtrain, ytrain).mean(),4)}.')\n",
    "    print(f'The training accuracy score is {round(model.score(xtrain, ytrain),4)}.')\n",
    "    print(f'The testing accuracy score is {round(model.score(xtest, ytest),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy_scores_gs(model, xtrain, ytrain, xtest, ytest):\n",
    "    print(f'The training accuracy score is {round(model.score(xtrain, ytrain),4)}.')\n",
    "    print(f'The testing accuracy score is {round(model.score(xtest, ytest),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cross_val_gs(model):\n",
    "    print(f'The cross_val score is {round(model.best_score_, 4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_sensitivity(actual_values, predicted_values):\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_values, predicted_values).ravel()\n",
    "    print(f'The training sensitivity score is {round(tp/(tp+fn), 4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_sensitivity(actual_values, predicted_values):\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_values, predicted_values).ravel()\n",
    "    print(f'The testing sensitivity score is {round(tp/(tp+fn), 4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = DummyClassifier(strategy = 'stratified', random_state = RANDOM_STATE) # Will respect training class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "null.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy and Sensitivity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation accuracy score is 0.501.\n",
      "The training accuracy score is 0.5051.\n",
      "The testing accuracy score is 0.5006.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores(null, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.5437.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, null.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.5397.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, null.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null model is making predictions in order to preserve the class distributions of the training set. In order to perform better than the null model, any models taht are built must perform better than 50.1% accuracy and ~54.0% sensitivity on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2a: Logistic Regression with No Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('logreg', LogisticRegression(penalty = 'none', solver = 'newton-cg', max_iter = 600))\n",
    "])\n",
    "\n",
    "# The model would not converge for the other solvers. Newton-cg can be used to fit larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': [nltk_stopwords],\n",
    "    'tfidf__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__tfidf__min_df': [3, 4, 5, 6, 7, 8],\n",
    "    'tfidf__tfidf__max_df': [0.30, 0.35, 0.40]\n",
    "}\n",
    "\n",
    "# Only best hyperparameters shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logreg_pipe = GridSearchCV(logreg_pipe, \n",
    "                              param_grid = logreg_pipe_params, \n",
    "                              cv = 5, \n",
    "                              verbose = 1, \n",
    "                              n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "gs_logreg_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for this model were determined to be a maximum occurrence in the data frame of 0.98, a minimum occurrence of 5, and and ngram range of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__tfidf__max_df': 0.3,\n",
       " 'tfidf__tfidf__min_df': 6,\n",
       " 'tfidf__tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__tfidf__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\"]}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7147.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_logreg_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.9996.\n",
      "The testing accuracy score is 0.7265.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(model = gs_logreg_pipe, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.9996.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_logreg_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.7265.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_logreg_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model performs better than baseline accuracy, this model is extremely overfit, but this is likely due to the large number of features in the model without any regularization. (Note: In this model, there are 3035 features (3030 are words and 5 are numerical features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2b: Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reg_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('ss', StandardScaler(with_mean = False)),\n",
    "    ('logreg', LogisticRegression(solver = 'liblinear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reg_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': [custom_stop_words],\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__tfidf__max_df': [0.65],\n",
    "    'tfidf__tfidf__min_df': [2],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__C': [0.0001]\n",
    "}\n",
    "# Only best params remain in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logreg_reg_pipe = GridSearchCV(logreg_reg_pipe, param_grid = logreg_reg_pipe_params, cv = 5, verbose=1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "gs_logreg_reg_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.0001,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'tfidf__tfidf__max_df': 0.65,\n",
       " 'tfidf__tfidf__min_df': 2,\n",
       " 'tfidf__tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__tfidf__stop_words': ['someon',\n",
       "  'll',\n",
       "  'like',\n",
       "  'know',\n",
       "  'ulpt',\n",
       "  'lpt',\n",
       "  'need',\n",
       "  'use',\n",
       "  'make',\n",
       "  'wa',\n",
       "  'way',\n",
       "  'peopl',\n",
       "  'ask',\n",
       "  'say',\n",
       "  'time',\n",
       "  'thi',\n",
       "  'want',\n",
       "  'work',\n",
       "  'just',\n",
       "  'start',\n",
       "  'ha',\n",
       "  'tri',\n",
       "  'becaus',\n",
       "  'onli',\n",
       "  'friend']}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_reg_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7841.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_logreg_reg_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.9949.\n",
      "The testing accuracy score is 0.7875.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(model = gs_logreg_reg_pipe, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 1.0.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_logreg_reg_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.8455.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_logreg_reg_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': [custom_stop_words],\n",
    "    'tfidf__tfidf__max_features': [7000],\n",
    "    'tfidf__tfidf__min_df': [3],\n",
    "    'tfidf__tfidf__max_df': [ 0.60],\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb_pipe = GridSearchCV(nb_pipe, param_grid = nb_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "gs_nb_pipe.fit(X_bayes_train, y_bayes_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Sensitivity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7827.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_nb_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.8962.\n",
      "The testing accuracy score is 0.7983.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(gs_nb_pipe, X_bayes_train, y_bayes_train, X_bayes_test, y_bayes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.9485.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_bayes_train, gs_nb_pipe.predict(X_bayes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.8789.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_bayes_test, gs_nb_pipe.predict(X_bayes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe_robust = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('rs', RobustScaler(with_centering = False)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# In this case, robust scaler performed better than standard scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words':['english'],\n",
    "    'tfidf__tfidf__min_df': [8],\n",
    "    'tfidf__tfidf__max_df': [0.45],\n",
    "    'tfidf__tfidf__ngram_range': [(1,1)],\n",
    "    'knn__n_neighbors' : [20],\n",
    "    'knn__metric':['euclidean'],\n",
    "    'knn__weights': ['distance']    \n",
    "}\n",
    "# Only best params remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_knn_pipe_robust = GridSearchCV(knn_pipe_robust, knn_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "gs_knn_pipe_robust.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6834779121238228"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn_pipe_robust.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 1.0.\n",
      "The testing accuracy score is 0.671.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(gs_knn_pipe_robust, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 1.0.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_knn_pipe_robust.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.762.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_knn_pipe_robust.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': ['english', nltk_stopwords, custom_stop_words],\n",
    "    'tfidf__tfidf__min_df': [2, 3, 4],\n",
    "    'tfidf__tfidf__max_df': [0.9, 0.95, 0.98],\n",
    "    'tfidf__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'dt__min_samples_split': [8, 9, 10],\n",
    "    'dt__min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt_pipe = GridSearchCV(dt_pipe, param_grid = dt_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/jocelynlutes/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2430 out of 2430 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "gs_dt_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__min_samples_leaf': 1,\n",
       " 'dt__min_samples_split': 9,\n",
       " 'tfidf__tfidf__max_df': 0.95,\n",
       " 'tfidf__tfidf__min_df': 2,\n",
       " 'tfidf__tfidf__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Sensitivity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.7098.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_dt_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.9812.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_dt_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6973646059237694"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768518518518519"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6829545454545455"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('bc', BaggingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_pipe_params = {\n",
    "    'tfidf__tfidf__min_df': [2, 3, 4],\n",
    "    'tfidf__tfidf__max_df': [0.9, 0.95, 0.98],\n",
    "    'tfidf__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bag_pipe = GridSearchCV(bag_pipe, param_grid = bag_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bag_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bag_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sensitivity(y_test, gs_bag_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
