{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_logreg_pipe.best_estimator_.steps[0][1].transformers_[0][1].get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score, confusion_matrix\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = pd.read_csv('../data/subreddits_preprocessed.csv')\n",
    "subreddits.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>original_text</th>\n",
       "      <th>post_length_char</th>\n",
       "      <th>post_length_words</th>\n",
       "      <th>is_unethical</th>\n",
       "      <th>stemmer_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>AlienAgency</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>: Answers to why</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>: answer to whi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>GarbageMiserable0x0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>¿Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>¿quier obten juego y premio grati en tu tiempo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit               author  num_comments  score   timestamp  \\\n",
       "0  LifeProTips          AlienAgency             2      1  2020-07-17   \n",
       "1  LifeProTips  GarbageMiserable0x0             2      1  2020-07-17   \n",
       "\n",
       "                                       original_text  post_length_char  \\\n",
       "0                                   : Answers to why                16   \n",
       "1  ¿Quieres obtener juegos y premios gratis en tu...                60   \n",
       "\n",
       "   post_length_words  is_unethical  \\\n",
       "0                  4             0   \n",
       "1                 10             0   \n",
       "\n",
       "                                        stemmer_text  polarity sentiment_cat  \n",
       "0                                    : answer to whi       0.0       Neutral  \n",
       "1  ¿quier obten juego y premio grati en tu tiempo...       0.0       Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate set of models, I determined that stemmed text and the Tfidf Vectorizer would be a good choice for my data. Therefore, I will conduct a train test split on the stemmed text and set up a Column Transformer to only vectorize my text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['num_comments', 'score', 'post_length_char', 'post_length_words', 'stemmer_text']\n",
    "#features = ['stemmer_text']\n",
    "X = subreddits[features]\n",
    "y = subreddits['is_unethical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for Multinomial Bayes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bayes = subreddits[['stemmer_text']]\n",
    "y_bayes = subreddits['is_unethical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bayes_train, X_bayes_test, y_bayes_train, y_bayes_test = train_test_split(X_bayes, y_bayes, test_size = 0.3, random_state = RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Stop Words Hyperparameter for Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = stopwords.words('english') + stopwords.words('spanish')\n",
    "custom_stop_words = nltk_stopwords + ['someon', 'll', 'like', 'know', 'ulpt', 'lpt', 'need', 'use', 'make', 'wa', 'way', 'peopl', 'ask', 'say', 'time', 'thi', 'want', 'work', 'just', 'start', 'ha', 'tri', 'becaus', 'onli', 'friend']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Column Transformer to Only Apply Vectorizer to Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(), 'stemmer_text'),], \n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARKDOWN TO DESCRIBE THE PROCESS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy_scores(model, xtrain, ytrain, xtest, ytest):\n",
    "    print(f'The cross validation accuracy score is {round(cross_val_score(model, xtrain, ytrain).mean(),4)}.')\n",
    "    print(f'The training accuracy score is {round(model.score(xtrain, ytrain),4)}.')\n",
    "    print(f'The testing accuracy score is {round(model.score(xtest, ytest),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy_scores_gs(model, xtrain, ytrain, xtest, ytest):\n",
    "    print(f'The training accuracy score is {round(model.score(xtrain, ytrain),4)}.')\n",
    "    print(f'The testing accuracy score is {round(model.score(xtest, ytest),4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cross_val_gs(model):\n",
    "    print(f'The cross_val score is {round(model.best_score_, 4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_sensitivity(actual_values, predicted_values):\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_values, predicted_values).ravel()\n",
    "    print(f'The training sensitivity score is {round(tp/(tp+fn), 4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_sensitivity(actual_values, predicted_values):\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_values, predicted_values).ravel()\n",
    "    print(f'The testing sensitivity score is {round(tp/(tp+fn), 4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = DummyClassifier(strategy = 'stratified', random_state = RANDOM_STATE) # Will respect training class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "null.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy and Sensitivity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation accuracy score is 0.501.\n",
      "The training accuracy score is 0.5051.\n",
      "The testing accuracy score is 0.5006.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores(null, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.5437.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, null.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.5397.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, null.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null model is making predictions in order to preserve the class distributions of the training set. In order to perform better than the null model, any models taht are built must perform better than 50.1% accuracy and ~54.0% sensitivity on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2a: Logistic Regression with No Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('logreg', LogisticRegression(penalty = 'none', solver = 'newton-cg', max_iter = 600))\n",
    "])\n",
    "\n",
    "# The model would not converge for the other solvers. Newton-cg can be used to fit larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': [nltk_stopwords],\n",
    "    'tfidf__tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__tfidf__min_df': [6],\n",
    "    'tfidf__tfidf__max_df': [0.25],\n",
    "    'tfidf__tfidf__max_features': [750]\n",
    "}\n",
    "\n",
    "# Only best hyperparameters shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logreg_pipe = GridSearchCV(logreg_pipe, \n",
    "                              param_grid = logreg_pipe_params, \n",
    "                              cv = 5, \n",
    "                              verbose = 1, \n",
    "                              n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   25.6s finished\n"
     ]
    }
   ],
   "source": [
    "gs_logreg_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__tfidf__max_df': 0.25,\n",
       " 'tfidf__tfidf__max_features': 750,\n",
       " 'tfidf__tfidf__min_df': 6,\n",
       " 'tfidf__tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__tfidf__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\",\n",
       "  'de',\n",
       "  'la',\n",
       "  'que',\n",
       "  'el',\n",
       "  'en',\n",
       "  'y',\n",
       "  'a',\n",
       "  'los',\n",
       "  'del',\n",
       "  'se',\n",
       "  'las',\n",
       "  'por',\n",
       "  'un',\n",
       "  'para',\n",
       "  'con',\n",
       "  'no',\n",
       "  'una',\n",
       "  'su',\n",
       "  'al',\n",
       "  'lo',\n",
       "  'como',\n",
       "  'más',\n",
       "  'pero',\n",
       "  'sus',\n",
       "  'le',\n",
       "  'ya',\n",
       "  'o',\n",
       "  'este',\n",
       "  'sí',\n",
       "  'porque',\n",
       "  'esta',\n",
       "  'entre',\n",
       "  'cuando',\n",
       "  'muy',\n",
       "  'sin',\n",
       "  'sobre',\n",
       "  'también',\n",
       "  'me',\n",
       "  'hasta',\n",
       "  'hay',\n",
       "  'donde',\n",
       "  'quien',\n",
       "  'desde',\n",
       "  'todo',\n",
       "  'nos',\n",
       "  'durante',\n",
       "  'todos',\n",
       "  'uno',\n",
       "  'les',\n",
       "  'ni',\n",
       "  'contra',\n",
       "  'otros',\n",
       "  'ese',\n",
       "  'eso',\n",
       "  'ante',\n",
       "  'ellos',\n",
       "  'e',\n",
       "  'esto',\n",
       "  'mí',\n",
       "  'antes',\n",
       "  'algunos',\n",
       "  'qué',\n",
       "  'unos',\n",
       "  'yo',\n",
       "  'otro',\n",
       "  'otras',\n",
       "  'otra',\n",
       "  'él',\n",
       "  'tanto',\n",
       "  'esa',\n",
       "  'estos',\n",
       "  'mucho',\n",
       "  'quienes',\n",
       "  'nada',\n",
       "  'muchos',\n",
       "  'cual',\n",
       "  'poco',\n",
       "  'ella',\n",
       "  'estar',\n",
       "  'estas',\n",
       "  'algunas',\n",
       "  'algo',\n",
       "  'nosotros',\n",
       "  'mi',\n",
       "  'mis',\n",
       "  'tú',\n",
       "  'te',\n",
       "  'ti',\n",
       "  'tu',\n",
       "  'tus',\n",
       "  'ellas',\n",
       "  'nosotras',\n",
       "  'vosotros',\n",
       "  'vosotras',\n",
       "  'os',\n",
       "  'mío',\n",
       "  'mía',\n",
       "  'míos',\n",
       "  'mías',\n",
       "  'tuyo',\n",
       "  'tuya',\n",
       "  'tuyos',\n",
       "  'tuyas',\n",
       "  'suyo',\n",
       "  'suya',\n",
       "  'suyos',\n",
       "  'suyas',\n",
       "  'nuestro',\n",
       "  'nuestra',\n",
       "  'nuestros',\n",
       "  'nuestras',\n",
       "  'vuestro',\n",
       "  'vuestra',\n",
       "  'vuestros',\n",
       "  'vuestras',\n",
       "  'esos',\n",
       "  'esas',\n",
       "  'estoy',\n",
       "  'estás',\n",
       "  'está',\n",
       "  'estamos',\n",
       "  'estáis',\n",
       "  'están',\n",
       "  'esté',\n",
       "  'estés',\n",
       "  'estemos',\n",
       "  'estéis',\n",
       "  'estén',\n",
       "  'estaré',\n",
       "  'estarás',\n",
       "  'estará',\n",
       "  'estaremos',\n",
       "  'estaréis',\n",
       "  'estarán',\n",
       "  'estaría',\n",
       "  'estarías',\n",
       "  'estaríamos',\n",
       "  'estaríais',\n",
       "  'estarían',\n",
       "  'estaba',\n",
       "  'estabas',\n",
       "  'estábamos',\n",
       "  'estabais',\n",
       "  'estaban',\n",
       "  'estuve',\n",
       "  'estuviste',\n",
       "  'estuvo',\n",
       "  'estuvimos',\n",
       "  'estuvisteis',\n",
       "  'estuvieron',\n",
       "  'estuviera',\n",
       "  'estuvieras',\n",
       "  'estuviéramos',\n",
       "  'estuvierais',\n",
       "  'estuvieran',\n",
       "  'estuviese',\n",
       "  'estuvieses',\n",
       "  'estuviésemos',\n",
       "  'estuvieseis',\n",
       "  'estuviesen',\n",
       "  'estando',\n",
       "  'estado',\n",
       "  'estada',\n",
       "  'estados',\n",
       "  'estadas',\n",
       "  'estad',\n",
       "  'he',\n",
       "  'has',\n",
       "  'ha',\n",
       "  'hemos',\n",
       "  'habéis',\n",
       "  'han',\n",
       "  'haya',\n",
       "  'hayas',\n",
       "  'hayamos',\n",
       "  'hayáis',\n",
       "  'hayan',\n",
       "  'habré',\n",
       "  'habrás',\n",
       "  'habrá',\n",
       "  'habremos',\n",
       "  'habréis',\n",
       "  'habrán',\n",
       "  'habría',\n",
       "  'habrías',\n",
       "  'habríamos',\n",
       "  'habríais',\n",
       "  'habrían',\n",
       "  'había',\n",
       "  'habías',\n",
       "  'habíamos',\n",
       "  'habíais',\n",
       "  'habían',\n",
       "  'hube',\n",
       "  'hubiste',\n",
       "  'hubo',\n",
       "  'hubimos',\n",
       "  'hubisteis',\n",
       "  'hubieron',\n",
       "  'hubiera',\n",
       "  'hubieras',\n",
       "  'hubiéramos',\n",
       "  'hubierais',\n",
       "  'hubieran',\n",
       "  'hubiese',\n",
       "  'hubieses',\n",
       "  'hubiésemos',\n",
       "  'hubieseis',\n",
       "  'hubiesen',\n",
       "  'habiendo',\n",
       "  'habido',\n",
       "  'habida',\n",
       "  'habidos',\n",
       "  'habidas',\n",
       "  'soy',\n",
       "  'eres',\n",
       "  'es',\n",
       "  'somos',\n",
       "  'sois',\n",
       "  'son',\n",
       "  'sea',\n",
       "  'seas',\n",
       "  'seamos',\n",
       "  'seáis',\n",
       "  'sean',\n",
       "  'seré',\n",
       "  'serás',\n",
       "  'será',\n",
       "  'seremos',\n",
       "  'seréis',\n",
       "  'serán',\n",
       "  'sería',\n",
       "  'serías',\n",
       "  'seríamos',\n",
       "  'seríais',\n",
       "  'serían',\n",
       "  'era',\n",
       "  'eras',\n",
       "  'éramos',\n",
       "  'erais',\n",
       "  'eran',\n",
       "  'fui',\n",
       "  'fuiste',\n",
       "  'fue',\n",
       "  'fuimos',\n",
       "  'fuisteis',\n",
       "  'fueron',\n",
       "  'fuera',\n",
       "  'fueras',\n",
       "  'fuéramos',\n",
       "  'fuerais',\n",
       "  'fueran',\n",
       "  'fuese',\n",
       "  'fueses',\n",
       "  'fuésemos',\n",
       "  'fueseis',\n",
       "  'fuesen',\n",
       "  'sintiendo',\n",
       "  'sentido',\n",
       "  'sentida',\n",
       "  'sentidos',\n",
       "  'sentidas',\n",
       "  'siente',\n",
       "  'sentid',\n",
       "  'tengo',\n",
       "  'tienes',\n",
       "  'tiene',\n",
       "  'tenemos',\n",
       "  'tenéis',\n",
       "  'tienen',\n",
       "  'tenga',\n",
       "  'tengas',\n",
       "  'tengamos',\n",
       "  'tengáis',\n",
       "  'tengan',\n",
       "  'tendré',\n",
       "  'tendrás',\n",
       "  'tendrá',\n",
       "  'tendremos',\n",
       "  'tendréis',\n",
       "  'tendrán',\n",
       "  'tendría',\n",
       "  'tendrías',\n",
       "  'tendríamos',\n",
       "  'tendríais',\n",
       "  'tendrían',\n",
       "  'tenía',\n",
       "  'tenías',\n",
       "  'teníamos',\n",
       "  'teníais',\n",
       "  'tenían',\n",
       "  'tuve',\n",
       "  'tuviste',\n",
       "  'tuvo',\n",
       "  'tuvimos',\n",
       "  'tuvisteis',\n",
       "  'tuvieron',\n",
       "  'tuviera',\n",
       "  'tuvieras',\n",
       "  'tuviéramos',\n",
       "  'tuvierais',\n",
       "  'tuvieran',\n",
       "  'tuviese',\n",
       "  'tuvieses',\n",
       "  'tuviésemos',\n",
       "  'tuvieseis',\n",
       "  'tuviesen',\n",
       "  'teniendo',\n",
       "  'tenido',\n",
       "  'tenida',\n",
       "  'tenidos',\n",
       "  'tenidas',\n",
       "  'tened']}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7032.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_logreg_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.8404.\n",
      "The testing accuracy score is 0.7176.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(model = gs_logreg_pipe, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.8491.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_logreg_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.7422.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_logreg_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model performs better than baseline accuracy, this model is extremely overfit, but this is likely due to the large number of features in the model without any regularization. (Note: In this model, there are 3035 features (3030 are words and 5 are numerical features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2b: Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reg_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('ss', StandardScaler(with_mean = False)),\n",
    "    ('logreg', LogisticRegression(solver = 'liblinear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reg_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': [custom_stop_words],\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__tfidf__max_df': [0.65],\n",
    "    'tfidf__tfidf__min_df': [2],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__C': [0.0001]\n",
    "}\n",
    "# Only best params remain in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logreg_reg_pipe = GridSearchCV(logreg_reg_pipe, param_grid = logreg_reg_pipe_params, cv = 5, verbose=1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "gs_logreg_reg_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7654.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_logreg_reg_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.9786.\n",
      "The testing accuracy score is 0.783.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(model = gs_logreg_reg_pipe, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.9915.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_logreg_reg_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.8434.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_logreg_reg_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': [nltk_stopwords],\n",
    "    'tfidf__tfidf__max_features': [6500],\n",
    "    'tfidf__tfidf__min_df': [3],\n",
    "    'tfidf__tfidf__max_df': [0.25],\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb_pipe = GridSearchCV(nb_pipe, param_grid = nb_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "gs_nb_pipe.fit(X_bayes_train, y_bayes_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__tfidf__max_df': 0.25,\n",
       " 'tfidf__tfidf__max_features': 6500,\n",
       " 'tfidf__tfidf__min_df': 3,\n",
       " 'tfidf__tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__tfidf__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\",\n",
       "  'de',\n",
       "  'la',\n",
       "  'que',\n",
       "  'el',\n",
       "  'en',\n",
       "  'y',\n",
       "  'a',\n",
       "  'los',\n",
       "  'del',\n",
       "  'se',\n",
       "  'las',\n",
       "  'por',\n",
       "  'un',\n",
       "  'para',\n",
       "  'con',\n",
       "  'no',\n",
       "  'una',\n",
       "  'su',\n",
       "  'al',\n",
       "  'lo',\n",
       "  'como',\n",
       "  'más',\n",
       "  'pero',\n",
       "  'sus',\n",
       "  'le',\n",
       "  'ya',\n",
       "  'o',\n",
       "  'este',\n",
       "  'sí',\n",
       "  'porque',\n",
       "  'esta',\n",
       "  'entre',\n",
       "  'cuando',\n",
       "  'muy',\n",
       "  'sin',\n",
       "  'sobre',\n",
       "  'también',\n",
       "  'me',\n",
       "  'hasta',\n",
       "  'hay',\n",
       "  'donde',\n",
       "  'quien',\n",
       "  'desde',\n",
       "  'todo',\n",
       "  'nos',\n",
       "  'durante',\n",
       "  'todos',\n",
       "  'uno',\n",
       "  'les',\n",
       "  'ni',\n",
       "  'contra',\n",
       "  'otros',\n",
       "  'ese',\n",
       "  'eso',\n",
       "  'ante',\n",
       "  'ellos',\n",
       "  'e',\n",
       "  'esto',\n",
       "  'mí',\n",
       "  'antes',\n",
       "  'algunos',\n",
       "  'qué',\n",
       "  'unos',\n",
       "  'yo',\n",
       "  'otro',\n",
       "  'otras',\n",
       "  'otra',\n",
       "  'él',\n",
       "  'tanto',\n",
       "  'esa',\n",
       "  'estos',\n",
       "  'mucho',\n",
       "  'quienes',\n",
       "  'nada',\n",
       "  'muchos',\n",
       "  'cual',\n",
       "  'poco',\n",
       "  'ella',\n",
       "  'estar',\n",
       "  'estas',\n",
       "  'algunas',\n",
       "  'algo',\n",
       "  'nosotros',\n",
       "  'mi',\n",
       "  'mis',\n",
       "  'tú',\n",
       "  'te',\n",
       "  'ti',\n",
       "  'tu',\n",
       "  'tus',\n",
       "  'ellas',\n",
       "  'nosotras',\n",
       "  'vosotros',\n",
       "  'vosotras',\n",
       "  'os',\n",
       "  'mío',\n",
       "  'mía',\n",
       "  'míos',\n",
       "  'mías',\n",
       "  'tuyo',\n",
       "  'tuya',\n",
       "  'tuyos',\n",
       "  'tuyas',\n",
       "  'suyo',\n",
       "  'suya',\n",
       "  'suyos',\n",
       "  'suyas',\n",
       "  'nuestro',\n",
       "  'nuestra',\n",
       "  'nuestros',\n",
       "  'nuestras',\n",
       "  'vuestro',\n",
       "  'vuestra',\n",
       "  'vuestros',\n",
       "  'vuestras',\n",
       "  'esos',\n",
       "  'esas',\n",
       "  'estoy',\n",
       "  'estás',\n",
       "  'está',\n",
       "  'estamos',\n",
       "  'estáis',\n",
       "  'están',\n",
       "  'esté',\n",
       "  'estés',\n",
       "  'estemos',\n",
       "  'estéis',\n",
       "  'estén',\n",
       "  'estaré',\n",
       "  'estarás',\n",
       "  'estará',\n",
       "  'estaremos',\n",
       "  'estaréis',\n",
       "  'estarán',\n",
       "  'estaría',\n",
       "  'estarías',\n",
       "  'estaríamos',\n",
       "  'estaríais',\n",
       "  'estarían',\n",
       "  'estaba',\n",
       "  'estabas',\n",
       "  'estábamos',\n",
       "  'estabais',\n",
       "  'estaban',\n",
       "  'estuve',\n",
       "  'estuviste',\n",
       "  'estuvo',\n",
       "  'estuvimos',\n",
       "  'estuvisteis',\n",
       "  'estuvieron',\n",
       "  'estuviera',\n",
       "  'estuvieras',\n",
       "  'estuviéramos',\n",
       "  'estuvierais',\n",
       "  'estuvieran',\n",
       "  'estuviese',\n",
       "  'estuvieses',\n",
       "  'estuviésemos',\n",
       "  'estuvieseis',\n",
       "  'estuviesen',\n",
       "  'estando',\n",
       "  'estado',\n",
       "  'estada',\n",
       "  'estados',\n",
       "  'estadas',\n",
       "  'estad',\n",
       "  'he',\n",
       "  'has',\n",
       "  'ha',\n",
       "  'hemos',\n",
       "  'habéis',\n",
       "  'han',\n",
       "  'haya',\n",
       "  'hayas',\n",
       "  'hayamos',\n",
       "  'hayáis',\n",
       "  'hayan',\n",
       "  'habré',\n",
       "  'habrás',\n",
       "  'habrá',\n",
       "  'habremos',\n",
       "  'habréis',\n",
       "  'habrán',\n",
       "  'habría',\n",
       "  'habrías',\n",
       "  'habríamos',\n",
       "  'habríais',\n",
       "  'habrían',\n",
       "  'había',\n",
       "  'habías',\n",
       "  'habíamos',\n",
       "  'habíais',\n",
       "  'habían',\n",
       "  'hube',\n",
       "  'hubiste',\n",
       "  'hubo',\n",
       "  'hubimos',\n",
       "  'hubisteis',\n",
       "  'hubieron',\n",
       "  'hubiera',\n",
       "  'hubieras',\n",
       "  'hubiéramos',\n",
       "  'hubierais',\n",
       "  'hubieran',\n",
       "  'hubiese',\n",
       "  'hubieses',\n",
       "  'hubiésemos',\n",
       "  'hubieseis',\n",
       "  'hubiesen',\n",
       "  'habiendo',\n",
       "  'habido',\n",
       "  'habida',\n",
       "  'habidos',\n",
       "  'habidas',\n",
       "  'soy',\n",
       "  'eres',\n",
       "  'es',\n",
       "  'somos',\n",
       "  'sois',\n",
       "  'son',\n",
       "  'sea',\n",
       "  'seas',\n",
       "  'seamos',\n",
       "  'seáis',\n",
       "  'sean',\n",
       "  'seré',\n",
       "  'serás',\n",
       "  'será',\n",
       "  'seremos',\n",
       "  'seréis',\n",
       "  'serán',\n",
       "  'sería',\n",
       "  'serías',\n",
       "  'seríamos',\n",
       "  'seríais',\n",
       "  'serían',\n",
       "  'era',\n",
       "  'eras',\n",
       "  'éramos',\n",
       "  'erais',\n",
       "  'eran',\n",
       "  'fui',\n",
       "  'fuiste',\n",
       "  'fue',\n",
       "  'fuimos',\n",
       "  'fuisteis',\n",
       "  'fueron',\n",
       "  'fuera',\n",
       "  'fueras',\n",
       "  'fuéramos',\n",
       "  'fuerais',\n",
       "  'fueran',\n",
       "  'fuese',\n",
       "  'fueses',\n",
       "  'fuésemos',\n",
       "  'fueseis',\n",
       "  'fuesen',\n",
       "  'sintiendo',\n",
       "  'sentido',\n",
       "  'sentida',\n",
       "  'sentidos',\n",
       "  'sentidas',\n",
       "  'siente',\n",
       "  'sentid',\n",
       "  'tengo',\n",
       "  'tienes',\n",
       "  'tiene',\n",
       "  'tenemos',\n",
       "  'tenéis',\n",
       "  'tienen',\n",
       "  'tenga',\n",
       "  'tengas',\n",
       "  'tengamos',\n",
       "  'tengáis',\n",
       "  'tengan',\n",
       "  'tendré',\n",
       "  'tendrás',\n",
       "  'tendrá',\n",
       "  'tendremos',\n",
       "  'tendréis',\n",
       "  'tendrán',\n",
       "  'tendría',\n",
       "  'tendrías',\n",
       "  'tendríamos',\n",
       "  'tendríais',\n",
       "  'tendrían',\n",
       "  'tenía',\n",
       "  'tenías',\n",
       "  'teníamos',\n",
       "  'teníais',\n",
       "  'tenían',\n",
       "  'tuve',\n",
       "  'tuviste',\n",
       "  'tuvo',\n",
       "  'tuvimos',\n",
       "  'tuvisteis',\n",
       "  'tuvieron',\n",
       "  'tuviera',\n",
       "  'tuvieras',\n",
       "  'tuviéramos',\n",
       "  'tuvierais',\n",
       "  'tuvieran',\n",
       "  'tuviese',\n",
       "  'tuvieses',\n",
       "  'tuviésemos',\n",
       "  'tuvieseis',\n",
       "  'tuviesen',\n",
       "  'teniendo',\n",
       "  'tenido',\n",
       "  'tenida',\n",
       "  'tenidos',\n",
       "  'tenidas',\n",
       "  'tened']}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_nb_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Sensitivity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7705.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_nb_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.902.\n",
      "The testing accuracy score is 0.7903.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(gs_nb_pipe, X_bayes_train, y_bayes_train, X_bayes_test, y_bayes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.953.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_bayes_train, gs_nb_pipe.predict(X_bayes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.8841.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_bayes_test, gs_nb_pipe.predict(X_bayes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe_robust = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('rs', RobustScaler(with_centering = False)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# In this case, robust scaler performed better than standard scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words':['english'],\n",
    "    'tfidf__tfidf__min_df': [8],\n",
    "    'tfidf__tfidf__max_df': [0.45],\n",
    "    'tfidf__tfidf__ngram_range': [(1,1)],\n",
    "    'knn__n_neighbors' : [20],\n",
    "    'knn__metric':['euclidean'],\n",
    "    'knn__weights': ['distance']    \n",
    "}\n",
    "# Only best params remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_knn_pipe_robust = GridSearchCV(knn_pipe_robust, knn_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "gs_knn_pipe_robust.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6834779121238228"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn_pipe_robust.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 1.0.\n",
      "The testing accuracy score is 0.671.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(gs_knn_pipe_robust, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 1.0.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_knn_pipe_robust.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.762.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_knn_pipe_robust.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words': ['english'],\n",
    "    'tfidf__tfidf__min_df': [2],\n",
    "    'tfidf__tfidf__max_df': [0.98],\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "    'dt__min_samples_split': [7],\n",
    "    'dt__min_samples_leaf': [1]\n",
    "}\n",
    "# Only best params shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt_pipe = GridSearchCV(dt_pipe, param_grid = dt_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    1.4s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "gs_dt_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__min_samples_leaf': 1,\n",
       " 'dt__min_samples_split': 7,\n",
       " 'tfidf__tfidf__max_df': 0.98,\n",
       " 'tfidf__tfidf__min_df': 2,\n",
       " 'tfidf__tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dt_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.6815.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_dt_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.982.\n",
      "The testing accuracy score is 0.675.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(gs_dt_pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training sensitivity score is 0.9852.\n"
     ]
    }
   ],
   "source": [
    "get_training_sensitivity(y_train, gs_dt_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.715.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_dt_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('bc', BaggingClassifier(random_state = RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_pipe_params = {\n",
    "    'tfidf__tfidf__stop_words':['english', nltk_stopwords],\n",
    "    'tfidf__tfidf__min_df': [2, 3, 4, 5, 6, 7, ],\n",
    "    'tfidf__tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "    'bc__n_estimators':[100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bag_pipe = RandomizedSearchCV(bag_pipe, param_distributions = bag_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.2min finished\n"
     ]
    }
   ],
   "source": [
    "gs_bag_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bc__n_estimators': 20,\n",
       " 'tfidf__tfidf__max_df': 0.7,\n",
       " 'tfidf__tfidf__min_df': 3,\n",
       " 'tfidf__tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross_val score is 0.7393.\n"
     ]
    }
   ],
   "source": [
    "display_cross_val_gs(gs_bag_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sensitivity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 1.0.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_train, gs_bag_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing sensitivity score is 0.7307.\n"
     ]
    }
   ],
   "source": [
    "get_testing_sensitivity(y_test, gs_bag_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('forest', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf_pipe_params = {\n",
    "    'tfidf__tfidf__'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784090909090909"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
