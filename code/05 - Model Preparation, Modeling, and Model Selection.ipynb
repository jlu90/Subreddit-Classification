{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = pd.read_csv('../data/subreddits_preprocessed.csv')\n",
    "subreddits.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>original_text</th>\n",
       "      <th>post_length_char</th>\n",
       "      <th>post_length_words</th>\n",
       "      <th>is_unethical</th>\n",
       "      <th>stemmer_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: Answers to why</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>AlienAgency</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>: Answers to why</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>: answer to whi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>GarbageMiserable0x0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>¿Quieres obtener juegos y premios gratis en tu...</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>¿quier obten juego y premio grati en tu tiempo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title selftext    subreddit  \\\n",
       "0                                   : Answers to why      NaN  LifeProTips   \n",
       "1  ¿Quieres obtener juegos y premios gratis en tu...      NaN  LifeProTips   \n",
       "\n",
       "                author  num_comments  score   timestamp  \\\n",
       "0          AlienAgency             2      1  2020-07-17   \n",
       "1  GarbageMiserable0x0             2      1  2020-07-17   \n",
       "\n",
       "                                       original_text  post_length_char  \\\n",
       "0                                   : Answers to why                16   \n",
       "1  ¿Quieres obtener juegos y premios gratis en tu...                60   \n",
       "\n",
       "   post_length_words  is_unethical  \\\n",
       "0                  4             0   \n",
       "1                 10             0   \n",
       "\n",
       "                                        stemmer_text  polarity sentiment_cat  \n",
       "0                                    : answer to whi       0.0       Neutral  \n",
       "1  ¿quier obten juego y premio grati en tu tiempo...       0.0       Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate set of models, I determined that stemmed text and the Tfidf Vectorizer would be a good choice for my data. Therefore, I will conduct a train test split on the stemmed text and set up a Column Transformer to only vectorize my text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['num_comments', 'score', 'post_length_char', 'post_length_words', 'polarity', 'stemmer_text']\n",
    "X = subreddits[features]\n",
    "y = subreddits['is_unethical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Stop Words Hyperparameter for Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = stopwords.words('english') + ['ulpt', 'lpt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Column Transformer to Only Apply Vectorizer to Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(stop_words = custom_stop_words), 'stemmer_text'),], \n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARKDOWN TO DESCRIBE THE PROCESS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy_scores(model, xtrain, ytrain, xtest, ytest):\n",
    "    print(f'The cross validation accuracy score is {cross_val_score(model, xtrain, ytrain).mean()}.')\n",
    "    print(f'The training accuracy score is {model.score(xtrain, ytrain)}.')\n",
    "    print(f'The testing accuracy score is {model.score(xtest, ytest)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy_scores_gs(model, xtrain, ytrain, xtest, ytest):\n",
    "    print(f'The training accuracy score is {model.score(xtrain, ytrain)}.')\n",
    "    print(f'The testing accuracy score is {model.score(xtest, ytest)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = DummyClassifier(strategy = 'stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "null.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation accuracy score is 0.5004860223998099.\n",
      "The training accuracy score is 0.50682261208577.\n",
      "The testing accuracy score is 0.5357954545454545.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores(model = null, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform better than the null model, any model that I build will need to perform better than 50.8% accuracy on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2a: Logistic Regression with No Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('logreg', LogisticRegression(penalty = 'none', solver = 'newton-cg', max_iter = 600))\n",
    "])\n",
    "\n",
    "# The model would not converge for the other solvers. Newton-cg can be used to fit larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_params = {\n",
    "    'tfidf__tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__tfidf__min_df': [5],\n",
    "    'tfidf__tfidf__max_df': [0.98]\n",
    "}\n",
    "\n",
    "# Note: All other hyperparameter options removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logreg_pipe = GridSearchCV(logreg_pipe, param_grid = logreg_pipe_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "gs_logreg_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__tfidf__max_df': 0.98,\n",
       " 'tfidf__tfidf__min_df': 5,\n",
       " 'tfidf__tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for this model were determined to be a maximum occurrence in the data frame of 0.98, a minimum occurrence of 5, and and ngram range of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927426398502718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.9990253411306043.\n",
      "The testing accuracy score is 0.70625.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(model = gs_logreg_pipe, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model performs better than baseline accuracy, this model is extremely overfit, but this is likely due to the large number of features in the model without any regularization. (Note: In this model, there are 3035 features (3030 are words and 5 are numerical features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2b: Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reg_pipe = Pipeline([\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('ss', StandardScaler(with_mean = False)),\n",
    "    ('logreg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Over Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reg_pipe_params = {\n",
    "    'tfidf__tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__tfidf__max_df': [0.90],\n",
    "    'tfidf__tfidf__min_df': [2],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__C': [0.0001, 0.00001, 0.000001],\n",
    "    'logreg__solver': ['liblinear']\n",
    "}\n",
    "# Only best params remain in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logreg_reg_pipe = GridSearchCV(logreg_reg_pipe, param_grid = logreg_reg_pipe_params, cv = 5, verbose=1, n_jobs = -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "gs_logreg_reg_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.0001,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'logreg__solver': 'liblinear',\n",
       " 'tfidf__tfidf__max_df': 0.9,\n",
       " 'tfidf__tfidf__min_df': 2,\n",
       " 'tfidf__tfidf__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg_reg_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross val score is 0.7712.\n"
     ]
    }
   ],
   "source": [
    "print(f'The cross val score is {round(gs_logreg_reg_pipe.best_score_, 4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy score is 0.9851364522417154.\n",
      "The testing accuracy score is 0.78125.\n"
     ]
    }
   ],
   "source": [
    "display_accuracy_scores_gs(model = gs_logreg_reg_pipe, xtrain = X_train, xtest = X_test, ytrain = y_train, ytest = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model has improved accuracy by about 8%, it is still very overfit to the training data. Reducing features in the vector of words and decreasing the C value even further do not seem to help. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pipe\n",
    "#### Grid Search Over Pipe\n",
    "#### Evaluate Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
